\subsubsection{Datenfusion MediaPipe und Kinect}

Sprint 2 realisierte die funktionale Integration beider Tracking-Systeme mit Fokus auf synchronisierte Datenverarbeitung und geometrische Bewegungsanalyse.

\subsubsection{Datenextraktion und Preprocessing}

\textbf{MediaPipe-Pipeline:}
\raggedright Die MediaPipe-Node generiert kontinuierlich aktualisierte \texttt{DAT}-Tabellen, die in node-spezifische Einzeltabellen segmentiert werden. Jede Tabelle enthält die räumlichen Koordinaten (\texttt{x}, \texttt{y}, \texttt{z}) sowie den \texttt{confidence}-Wert für die Tracking-Zuverlässigkeit.

\textbf{Kinect-Integration:}
\raggedright Parallele Formatierung der Kinect-Daten zur MediaPipe-Kompatibilität mit anschließender Node-Zuordnung zwischen beiden Systemen.

\textbf{Datenfusion:}
\raggedright Ein Python-basierter Fusionsalgorithmus implementiert Kalman-Filter-Glättung und temporale Synchronisation der Positionsdaten. Darauf basierend werden geometrische Parameter (Distanzen, Winkel) zwischen definierten Gelenkpaaren berechnet.



\subsubsection{Komparative Tracking-Evaluation}

\textbf{Testsetup:}
Simultanes MediaPipe- und Kinect-Tracking über gemeinsame RGB-Kamera der Kinect V2.

\textbf{Testumgebung:}
\begin{itemize}
    \item \textbf{TouchDesigner-Interface:} Das komparative Testing-Interface
    \item \textbf{Repository:} \texttt{Testing\_KinectVsMediapipe.toe}
\end{itemize}


\textbf{Evaluationsergebnisse:}
\raggedright MediaPipe demonstriert deutlich verbesserte Robustheit bei partieller Okklusion. Das ML-Modell generiert höhere Confidence-Werte für nicht-sichtbare Körperregionen (z.B. bei Rotationsbewegungen) im Vergleich zur nativen Kinect-Hardware-Implementierung.

\textbf{Technische Implikationen:}
\begin{itemize}
    \item MediaPipe eignet sich als primäres Tracking-System für komplexe Choreographien
    \item Kinect V2 fungiert als Backup-System und Tiefendatenquelle
    \item Hybride Implementierung maximiert Tracking-Reliabilität
\end{itemize}